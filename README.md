### This repository contains the code presented in the work “SIMMA: Multimodal Automatic Depression Detection via Spatiotemporal Ensemble and Cross-Modal Alignment” by Yaowei Wang, Zulong Lin, Yan Teng, Yuqi Cheng, Hongyan Jiang, and Yun Yang. (TCSS 2025)

#### You can run the code as follows: udio
1. Install all the packages you need in the requirements.txt.
2. According to the prompts in the paper, the time series features of face and audio are extracted from the depression videos.
3. Load the time series features and run main.py.

#### If you find this repository useful in your research, please cite:
@article{wang2025simma,
  title={Simma: Multimodal automatic depression detection via spatiotemporal ensemble and cross-modal alignment},
  author={Wang, Yaowei and Lin, Zulong and Teng, Yan and Cheng, Yuqi and Jiang, Hongyan and Yang, Yun},
  journal={IEEE Transactions on Computational Social Systems},
  year={2025},
  publisher={IEEE}
}
